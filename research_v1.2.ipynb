{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "1f5b50453fd9f372111fc96a665fefebae91c58c2c5b56303c56eabba6b14ae0"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *\n",
    "import string\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import coo_matrix, hstack\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_businesses = [line.strip() for line in open(\"list_of_businesses.txt\", 'r')]\n",
    "list_hs_codes = [line.strip() for line in open(\"list_hs_codes.txt\", 'r')]\n",
    "list_strengthes = [line.strip() for line in open(\"list_strengthes.txt\", 'r')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(path, status):\n",
    "    \"\"\"\n",
    "    path, str to dataset, e.g 'model_passed_review.csv'\n",
    "    status, could be 'passed' or 'failed'\n",
    "    e.g. prepare_data('model_passed_review.csv', 'passed')\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path, header = None)\n",
    "    \n",
    "    df = df.drop([4, 5], axis=1)\n",
    "    df = df.rename(columns=\n",
    "                       {0 : \"Business\", \n",
    "                        1 : \"Part_number\",\n",
    "                        2 : \"Part_description\",\n",
    "                        3 : \"HS_code\",\n",
    "                        6 : \"Audit_trail\",\n",
    "                        7 : \"Strength\"})\n",
    "    df = df.drop_duplicates(subset=['Audit_trail', 'HS_code']).reset_index(drop=True)\n",
    "    df = df.fillna('missed_data')\n",
    "    df['HS_code'] = df['HS_code'].astype('str')\n",
    "    df['Strength'] = df['Strength'].astype('str')\n",
    "    #converting the \n",
    "    df['Business'] = df['Business'].apply(lambda x: x if x in list_businesses else 'unknown')\n",
    "    df['HS_code'] = df['HS_code'].apply(lambda x: x if x in list_hs_codes else 'unknown')\n",
    "    df['Strength'] = df['Strength'].apply(lambda x: x if x in list_strengthes else 'unknown')\n",
    "    #adding the label\n",
    "    if status == \"passed\":\n",
    "        df['Failed'] = 0\n",
    "    else:\n",
    "        df['Failed'] = 1\n",
    "    df_text = df['Part_number'] + \" \" + df['Part_description'] + \" \" + df['Audit_trail']\n",
    "    df_features = df[['Business', 'HS_code', 'Strength']]\n",
    "    y = df['Failed']\n",
    "\n",
    "    return df_text, df_features, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "passed_text, passed_features, y_passed = prepare_data('model_passed_review.csv', 'passed')\n",
    "failed_text, failed_features, y_failed = prepare_data('model_failed_review.csv', 'failed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_text = pd.concat([passed_text, failed_text], ignore_index=True)\n",
    "df_train_features = pd.concat([passed_features, failed_features], ignore_index=True)\n",
    "y_train = pd.concat([y_passed, y_failed], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(categories=(list_businesses, list_hs_codes, list_strengthes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<66302x1366 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 198906 stored elements in Compressed Sparse Row format>"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "df_train_features = enc.fit_transform(df_train_features)\n",
    "df_train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "df_train_features.shape[1] == len(list_businesses) + len(list_hs_codes) + len(list_strengthes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_URL(text):\n",
    "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url.sub(r'',text)\n",
    "\n",
    "def remove_punct(text):\n",
    "    table = str.maketrans('','',string.punctuation)\n",
    "    return text.translate(table)\n",
    "\n",
    "cachedStopWords = stopwords.words(\"english\")\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    text = ' '.join([word for word in text.split() if word not in cachedStopWords])\n",
    "    return text\n",
    "\n",
    "stemmer = SnowballStemmer('english')\n",
    "#stemmer = PorterStemmer()\n",
    "#lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The function takes as input dataset and columns to process\n",
    "def clean_data(df):\n",
    "    df = df.apply(lambda x : remove_URL(x))\n",
    "    df = df.apply(lambda x : remove_punct(x))\n",
    "    df = df.apply(lambda x : remove_stopwords(x))\n",
    "    df = df.apply(lambda x : stemmer.stem(x))\n",
    "    # df = df.apply(lambda x : lemmatizer.lemmatize(x))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "text reducing is  0.7957101890654006\n"
     ]
    }
   ],
   "source": [
    "df_cleaned_train_text = clean_data(df_train_text)\n",
    "print('text reducing is ', len(\" \".join(df_cleaned_train_text))/len(\" \".join(df_train_text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_DF = 0.8\n",
    "MIN_COUNT = 5\n",
    "NGRAMS = (1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN_RE = re.compile(r'[a-z]+|-?\\d*[-.,]?\\d+|\\S')\n",
    "\n",
    "def tokenize_text_simple_regex(txt, min_token_size=2):\n",
    "    txt = txt.lower()\n",
    "    all_tokens = TOKEN_RE.findall(txt)\n",
    "\n",
    "    return [token for token in all_tokens if len(token) >= min_token_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TfidfVectorizer(max_df=0.8, min_df=5,\n",
       "                tokenizer=<function tokenize_text_simple_regex at 0x0000026412DBBE50>)"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "vector = TfidfVectorizer(tokenizer=tokenize_text_simple_regex,\n",
    "                            min_df=MIN_COUNT, max_df=MAX_DF,\n",
    "                            ngram_range = NGRAMS)\n",
    "vector.fit(df_cleaned_train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_words(corpus, n=None):\n",
    "\n",
    "    vec = CountVectorizer().fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in     vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('per', 94695),\n",
       " ('it', 42820),\n",
       " ('not', 30120),\n",
       " ('steel', 27997),\n",
       " ('used', 26647),\n",
       " ('this', 24443),\n",
       " ('part', 20537),\n",
       " ('made', 19849),\n",
       " ('engineer', 17994),\n",
       " ('plm', 16537)]"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "get_top_n_words(df_cleaned_train_text, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<66302x18341 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1700558 stored elements in Compressed Sparse Row format>"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "df_cleaned_train_text = vector.transform(df_cleaned_train_text)\n",
    "df_cleaned_train_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total = hstack([df_train_features, df_cleaned_train_text])\n",
    "y = pd.concat([y_passed, y_failed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_holdout, y_train, y_holdout = train_test_split(df_total, y, \n",
    "                                                          test_size=0.3, \n",
    "                                                          random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "F1 score (train) 0.778\nF1 score (holdout) 0.702\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=SEED).fit(X_train, y_train)\n",
    "print('F1 score (train) %.3f' % f1_score(y_train, clf.predict(X_train)))\n",
    "print('F1 score (holdout) %.3f' % f1_score(y_holdout, clf.predict(X_holdout)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "F1 score (train) 0.834\nF1 score (holdout) 0.711\n"
     ]
    }
   ],
   "source": [
    "clf2 = RidgeClassifier(random_state=SEED).fit(X_train, y_train)\n",
    "print('F1 score (train) %.3f' % f1_score(y_train, clf2.predict(X_train)))\n",
    "print('F1 score (holdout) %.3f' % f1_score(y_holdout, clf2.predict(X_holdout)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "F1 score (train) 0.706\nF1 score (holdout) 0.655\n"
     ]
    }
   ],
   "source": [
    "clf3 = MultinomialNB().fit(X_train, y_train)\n",
    "print('F1 score (train) %.3f' % f1_score(y_train, clf3.predict(X_train)))\n",
    "print('F1 score (holdout) %.3f' % f1_score(y_holdout, clf3.predict(X_holdout)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "F1 score (train) 0.859\nF1 score (holdout) 0.717\n"
     ]
    }
   ],
   "source": [
    "clf4 = svm.LinearSVC(random_state=SEED).fit(X_train, y_train)\n",
    "print('F1 score (train) %.3f' % f1_score(y_train, clf4.predict(X_train)))\n",
    "print('F1 score (holdout) %.3f' % f1_score(y_holdout, clf4.predict(X_holdout)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_passed_text, test_passed_features, y_passed_test = prepare_data('test_passed_review.csv', 'passed')\n",
    "test_failed_text, test_failed_features, y_failed_test = prepare_data('test_failed_review.csv', 'failed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_text = pd.concat([test_passed_text, test_failed_text], ignore_index=True)\n",
    "df_test_features = pd.concat([test_passed_features, test_failed_features], ignore_index=True)\n",
    "y_test = pd.concat([y_passed_test, y_failed_test], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<42767x1366 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 128301 stored elements in Compressed Sparse Row format>"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "df_test_features = enc.transform(df_test_features)\n",
    "df_test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": [
    "df_test_features.shape[1] == len(list_businesses) + len(list_hs_codes) + len(list_strengthes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "text reducing is  0.7911105632121019\n"
     ]
    }
   ],
   "source": [
    "df_cleaned_test_text = clean_data(df_test_text)\n",
    "print('text reducing is ', len(\" \".join(df_cleaned_test_text))/len(\" \".join(df_test_text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<66302x18341 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1700558 stored elements in Compressed Sparse Row format>"
      ]
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "source": [
    "df_cleaned_test_text = vector.transform(df_cleaned_test_text)\n",
    "df_cleaned_train_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = hstack([df_test_features, df_cleaned_test_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Logistic regression F1 score (test) 0.606\nRidge Clasifier F1 score (test) 0.593\nNaive Bayes F1 score (test) 0.575\nLinear SVM F1 score (test) 0.595\n"
     ]
    }
   ],
   "source": [
    "print('Logistic regression F1 score (test) %.3f' % f1_score(y_test, clf.predict(X_test)))\n",
    "print('Ridge Clasifier F1 score (test) %.3f' % f1_score(y_test, clf2.predict(X_test)))\n",
    "print('Naive Bayes F1 score (test) %.3f' % f1_score(y_test, clf3.predict(X_test)))\n",
    "print('Linear SVM F1 score (test) %.3f' % f1_score(y_test, clf4.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}